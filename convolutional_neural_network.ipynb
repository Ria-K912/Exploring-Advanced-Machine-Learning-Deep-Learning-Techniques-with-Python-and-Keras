{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCV30xyVhFbE"
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIleuCAjoFD8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.12.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting keras\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "                                              0.0/1.7 MB ? eta -:--:--\n",
      "                                              0.0/1.7 MB 1.3 MB/s eta 0:00:02\n",
      "     -                                        0.1/1.7 MB 812.7 kB/s eta 0:00:03\n",
      "     --                                       0.1/1.7 MB 901.1 kB/s eta 0:00:02\n",
      "     ----                                     0.2/1.7 MB 1.1 MB/s eta 0:00:02\n",
      "     ------                                   0.3/1.7 MB 1.3 MB/s eta 0:00:02\n",
      "     --------                                 0.4/1.7 MB 1.3 MB/s eta 0:00:02\n",
      "     -----------                              0.5/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------                          0.7/1.7 MB 1.7 MB/s eta 0:00:01\n",
      "     -------------------                      0.8/1.7 MB 1.8 MB/s eta 0:00:01\n",
      "     ------------------------                 1.0/1.7 MB 2.1 MB/s eta 0:00:01\n",
      "     ----------------------------             1.2/1.7 MB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------          1.4/1.7 MB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------------    1.6/1.7 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.7/1.7 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "Successfully installed keras-2.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -iskit-terra (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -iskit-terra (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.12.0 requires keras<2.13,>=2.12.0, but you have keras 2.13.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0koUcJMJpEBD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the Training set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\Section+40+-+Convolutional+Neural+Networks+(CNN)\\\\Section 40 - Convolutional Neural Networks (CNN)\\\\dataset\\\\training_set\",\n",
    "                                              target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SH4WzfOhpKc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the Test Set\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\Section+40+-+Convolutional+Neural+Networks+(CNN)\\\\Section 40 - Convolutional Neural Networks (CNN)\\\\dataset\\\\test_set\",\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAUt4UMPlhLS"
   },
   "outputs": [],
   "source": [
    "#Initialising the CNN\n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XPzPrMckl-hV"
   },
   "outputs": [],
   "source": [
    "#Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncpqPl69mOac"
   },
   "outputs": [],
   "source": [
    "#Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_-FZjn_m8gk"
   },
   "outputs": [],
   "source": [
    "#Adding a second convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a third convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AZeOGCvnNZn"
   },
   "outputs": [],
   "source": [
    "#Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GtmUlLd26Nq"
   },
   "outputs": [],
   "source": [
    "#Full Connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1p_Zj1Mc3Ko_"
   },
   "outputs": [],
   "source": [
    "#output layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NALksrNQpUlJ"
   },
   "outputs": [],
   "source": [
    "#Compiling the CNN\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XUj1W4PJptta"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 133s 525ms/step - loss: 0.6573 - accuracy: 0.5924 - val_loss: 0.5993 - val_accuracy: 0.6775\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 60s 240ms/step - loss: 0.6054 - accuracy: 0.6693 - val_loss: 0.5576 - val_accuracy: 0.7155\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.5571 - accuracy: 0.7214 - val_loss: 0.5130 - val_accuracy: 0.7470\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.5118 - accuracy: 0.7490 - val_loss: 0.4795 - val_accuracy: 0.7680\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.4889 - accuracy: 0.7596 - val_loss: 0.4783 - val_accuracy: 0.7710\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.4750 - accuracy: 0.7659 - val_loss: 0.4528 - val_accuracy: 0.7835\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.4512 - accuracy: 0.7859 - val_loss: 0.4393 - val_accuracy: 0.8005\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.4369 - accuracy: 0.7960 - val_loss: 0.4660 - val_accuracy: 0.7840\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 62s 248ms/step - loss: 0.4233 - accuracy: 0.8062 - val_loss: 0.4464 - val_accuracy: 0.7955\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 63s 252ms/step - loss: 0.4060 - accuracy: 0.8142 - val_loss: 0.4203 - val_accuracy: 0.8100\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 63s 253ms/step - loss: 0.3882 - accuracy: 0.8202 - val_loss: 0.4173 - val_accuracy: 0.8085\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 0.3758 - accuracy: 0.8249 - val_loss: 0.3969 - val_accuracy: 0.8200\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 70s 281ms/step - loss: 0.3620 - accuracy: 0.8361 - val_loss: 0.3916 - val_accuracy: 0.8245\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 69s 278ms/step - loss: 0.3474 - accuracy: 0.8429 - val_loss: 0.3935 - val_accuracy: 0.8170\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 62s 246ms/step - loss: 0.3312 - accuracy: 0.8515 - val_loss: 0.4714 - val_accuracy: 0.7830\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 62s 249ms/step - loss: 0.3207 - accuracy: 0.8540 - val_loss: 0.3988 - val_accuracy: 0.8290\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 61s 246ms/step - loss: 0.3001 - accuracy: 0.8669 - val_loss: 0.3864 - val_accuracy: 0.8245\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 62s 247ms/step - loss: 0.2927 - accuracy: 0.8720 - val_loss: 0.3890 - val_accuracy: 0.8300\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 60s 240ms/step - loss: 0.2812 - accuracy: 0.8766 - val_loss: 0.4113 - val_accuracy: 0.8210\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 61s 244ms/step - loss: 0.2650 - accuracy: 0.8857 - val_loss: 0.3900 - val_accuracy: 0.8265\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 0.2575 - accuracy: 0.8907 - val_loss: 0.4541 - val_accuracy: 0.8270\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.2469 - accuracy: 0.8938 - val_loss: 0.4348 - val_accuracy: 0.8160\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 0.2306 - accuracy: 0.9051 - val_loss: 0.4068 - val_accuracy: 0.8370\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 643s 3s/step - loss: 0.2214 - accuracy: 0.9085 - val_loss: 0.4304 - val_accuracy: 0.8335\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 0.2169 - accuracy: 0.9071 - val_loss: 0.4523 - val_accuracy: 0.8235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x222f4d31fc0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the CNN on the Training set and evaluating it on the Test set\n",
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsSiWEJY1BPB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000222F145E3B0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x00000222F145E3B0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000222F145E3B0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x00000222F145E3B0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 333ms/step\n"
     ]
    }
   ],
   "source": [
    "#Making a single prediction\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\Section+40+-+Convolutional+Neural+Networks+(CNN)\\\\Section 40 - Convolutional Neural Networks (CNN)\\\\dataset\\\\single_prediction\\\\cat_or_dog_1.jpg\", target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog'\n",
    "else:\n",
    "  prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ED9KB3I54c1i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img(\"C:\\\\Users\\\\Hp\\\\Downloads\\\\Section+40+-+Convolutional+Neural+Networks+(CNN)\\\\Section 40 - Convolutional Neural Networks (CNN)\\\\dataset\\\\single_prediction\\\\cat_or_dog_2.jpg\", target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog'\n",
    "else:\n",
    "  prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "convolutional_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
